{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tools as t\n",
    "import scipy.stats\n",
    "import math\n",
    "from collections import Counter\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sub_vec( x,y ):\n",
    "    return [  y[i] - x[i]   for i in xrange(len(x)) ]\n",
    "def calulate_entropies_numerical(  row , N  ):\n",
    "    row_sum = sum(row)\n",
    "    entropy = 0\n",
    "    for i,v in enumerate(row):\n",
    "        if v > 0:\n",
    "            p = float( v ) / row_sum\n",
    "            entropy+= p*math.log(p,2)\n",
    "    \n",
    "    p_subset = float( row_sum) /N\n",
    "    entropy =  p_subset * abs( entropy)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculating entropies\n",
    "def calulate_entropies_categorical( splits, table,n ,unique_classes):\n",
    "    #print \"Evaluating Split: \",splits\n",
    "    #print \"Unique_classes\", unique_classes\n",
    "    #print table\n",
    "    entropy = 0\n",
    "    chota_n = 0\n",
    "    \n",
    "    for aik_class in unique_classes:\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        \n",
    "        if isinstance( splits, str ):\n",
    "            #print  \"len of splits\", len(splits),\" splits\" , splits\n",
    "            numerator+= table[ splits ][aik_class]\n",
    "            denominator+= sum( table[splits  ].values())\n",
    "            #print \"Numerator\" ,numerator  ,\"Denum \", denominator\n",
    "        else:\n",
    "            for i in xrange( len(splits)):\n",
    "                #print \"Claaass \", aik_class ,\" Split Value \", splits[i]\n",
    "                numerator+= table[ splits[i] ][aik_class]\n",
    "                denominator+= sum( table[splits[i]  ].values())\n",
    "                #print \"Numerator\" ,numerator  ,\"Denum \", denominator\n",
    "            \n",
    "        #print \"num \", numerator , \" den\" , denominator\n",
    "        chota_n = denominator\n",
    "        \n",
    "        if numerator > 0:\n",
    "            p = float(numerator ) / denominator\n",
    "            entropy += p * math.log(p,2)\n",
    "    \n",
    "    #print \"simple entropy\" , entropy\n",
    "    #print \"chota_n\" , chota_n , \"bara_n\" , n , \"abs_entropy_withput_p\", abs(  entropy )\n",
    "    subset_p = float(chota_n) / n\n",
    "    #print \"entropy \",  subset_p * abs(  entropy )     \n",
    "    \n",
    "    return subset_p * abs(  entropy )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,purity,klasslabel='',score=0,split=[],fidx=-1):\n",
    "        self.lchild=None       \n",
    "        self.rchild=None\n",
    "        self.klasslabel=klasslabel        \n",
    "        self.split=split\n",
    "        self.score=score\n",
    "        self.fidx=fidx\n",
    "        self.purity=purity\n",
    "        self.f_type= None\n",
    "        self.leaf = False\n",
    "        \n",
    "    def set_childs(self,lchild,rchild):\n",
    "        self.lchild=lchild      \n",
    "        self.rchild=rchild\n",
    "        \n",
    "    def isleaf(self):\n",
    "        return self.leaf\n",
    "    def isless_than_eq(self, X):\n",
    "        if X[self.fidx]<=self.split: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def get_str(self):        \n",
    "        if self.isleaf():\n",
    "            return 'C(class={},Purity={})'.format(self.klasslabel,self.purity)\n",
    "        else:\n",
    "            return 'I(Fidx={},Score={},Split={})'.format(self.fidx,self.score,self.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSplits(categories):\n",
    "    categories=set(categories)\n",
    "    tsplits=t.get_powerset(categories,len(categories)-1) # get all the power sets with the given cardinality...\n",
    "    flist=[]\n",
    "    for s in tsplits:\n",
    "        if not s in flist:\n",
    "            r=categories.difference(s)\n",
    "            flist.append(s)\n",
    "            flist.append(r)\n",
    "    olist=[]\n",
    "    for s in flist:\n",
    "        ilist=[]\n",
    "        for k in s:\n",
    "            ilist.append(k)\n",
    "        olist.append(tuple(ilist))\n",
    "    return olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, purityp, exthreshold, maxdepth=10):        \n",
    "        self.purity = purityp\n",
    "        self.exthreshold = exthreshold\n",
    "        self.maxdepth = maxdepth\n",
    "        pass\n",
    "    def test(self, X):\n",
    "        nexamples, nfeatures=X.shape\n",
    "        pclasses=self.predict(X)\n",
    "        return pclasses\n",
    "    def predict(self, X):\n",
    "        z=[]\n",
    "        #print \"Numver of rows to preduct \", X.shape[0]\n",
    "        for idx in range(X.shape[0]):\n",
    "            z.append(self._predict(self.tree,X[idx]))\n",
    "        return np.array( z )\n",
    "    def _predict(self,node, X):\n",
    "        #print X\n",
    "      \n",
    "        temp=self.tree\n",
    "        while temp!=None:\n",
    "            if temp.f_type == \"categorical\":\n",
    "                #print \"cat\"\n",
    "                if np.in1d(X[temp.fidx],temp.split  ):\n",
    "                    #print \"l\"\n",
    "                    temp=temp.lchild\n",
    "                else:\n",
    "                    #print \"r\"\n",
    "                    temp=temp.rchild\n",
    "            elif temp.f_type == \"numerical\":\n",
    "                #print \"num\"\n",
    "                if X[temp.fidx] >temp.split:\n",
    "                    #print \"r\"\n",
    "                    temp=temp.rchild\n",
    "                else :\n",
    "                    #print \"l\"\n",
    "                    temp=temp.lchild\n",
    "            else:\n",
    "                #print \"The class i got is\", temp.klasslabel\n",
    "                return temp.klasslabel\n",
    "    def train(self, X, Y):\n",
    "        nexamples, nfeatures = X.shape\n",
    "        # # now go and train a model for each class...\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        self.tree = self.build_tree(X,Y,0)\n",
    "        return\n",
    "    \n",
    "    def build_tree(self, X, Y, depth):\n",
    "        nexamples, nfeatures = X.shape \n",
    "        #print \"BUILD TREE \" , nexamples ,\" number of rows\" \n",
    "        klasses, sizekclasses =np.unique(Y, return_counts=True);\n",
    "        #print klasses, sizekclasses\n",
    "       \n",
    "        purities = [float(n)/nexamples  for n in sizekclasses]\n",
    "        #print purities\n",
    "        \n",
    "        nodePurity = max (purities)\n",
    "        klabel = np.argmax(purities)\n",
    "        \n",
    "        thisNode = Node(nodePurity)\n",
    "\n",
    "        if nexamples<=self.exthreshold or nodePurity>= self.purity or self.maxdepth<=depth+1:\n",
    "            #print \"Class assigned is\",klasses[klabel]\n",
    "            thisNode.klasslabel = klasses[klabel]\n",
    "            thisNode.leaf = True\n",
    "            return thisNode\n",
    "        \n",
    "        split, gain, left, right, fidx, f_type = 0,0,None, None, 0,None\n",
    "        \n",
    "        # not specifying feature 14 and not using nfeatures becasue to takes too long\n",
    "        for f in range(nfeatures):\n",
    "            if isinstance(X[0,f],long):\n",
    "                gain1 , split1  = self.evaluate_numerical_attribute(X[:,f],Y) \n",
    "                f_type1 = \"numerical\"\n",
    "                #print \"Numerical fidx\" , f , \" Gain \", gain1\n",
    "            else:\n",
    "                ## TODO: REMOVE COMMENT\n",
    "                #gain1 , split1 = -1 , []\n",
    "                gain1 , split1 = self.evaluate_categorical_attribute(X[:,f],Y) \n",
    "                f_type1 = \"categorical\"\n",
    "                #print \"Categorical fidx\" , f , \" Gain \", gain1\n",
    "            if gain1 > gain:\n",
    "                fidx =f\n",
    "                gain = gain1\n",
    "                split = split1\n",
    "                f_type = f_type1\n",
    "                # yahin par masla hai\n",
    "                #left = left1\n",
    "                #right = right1\n",
    "        thisNode.fidx = fidx\n",
    "        thisNode.score = gain\n",
    "        thisNode.split = split\n",
    "        thisNode.f_type = f_type\n",
    "        \n",
    "        # if attribute is categorical then manage differently\n",
    "        lchild , rchild = None, None\n",
    "        if f_type == \"categorical\":\n",
    "            #print \"Best gain at categorical feature \" , fidx, \" \", split, \" \",gain\n",
    "            mask = np.in1d(X[:,fidx],split  )\n",
    "            inv_mask = np.invert(mask)\n",
    "        else:\n",
    "            #print \"Best gain at numerical feature \" , fidx, \" \", split, \" \",gain\n",
    "            mask = X[: ,fidx] <= split\n",
    "            inv_mask = np.invert(mask)\n",
    "        \n",
    "        #print \"Left \", len(X[mask]) , \"Right\", len(X[inv_mask])\n",
    "        \n",
    "        \n",
    "        #for i in xrange( len(X[mask]) ):\n",
    "        #    print X[i], \" \", Y[i]\n",
    "        # if there is no left child\n",
    "        \n",
    "        if len( X[inv_mask] ) == 0 :\n",
    "            #print \"Nothing for DN\",  \" So class assigned is \", klasses[klabel]\n",
    "            thisNode.klasslabel = klasses[klabel]\n",
    "            thisNode.leaf = True\n",
    "            thisNode.score = 0\n",
    "            thisNode.split = None\n",
    "            thisNode.f_type = None\n",
    "            \n",
    "            return thisNode\n",
    "        else: \n",
    "            lchild = self.build_tree( X[mask],Y[mask],depth+1 )    \n",
    "            rchild = self.build_tree( X[inv_mask],Y[inv_mask],depth+1 )\n",
    "        \n",
    "        thisNode.set_childs(lchild,rchild)\n",
    "        return thisNode\n",
    "        ''' continue buildtree\n",
    "        if gain==99:\n",
    "            thisNode.klasslabel = klasses[klabel]\n",
    "            thisNode.leaf = True\n",
    "            return thisNode\n",
    "        '''\n",
    "     \n",
    "        \n",
    "    def evaluate_categorical_attribute(self,feat, y):\n",
    "        x =  feat.ravel()\n",
    "        y = y.ravel()\n",
    "        # Datastructure\n",
    "        table = defaultdict( lambda: defaultdict(int) )\n",
    "        for i in xrange( len(x) ):\n",
    "            table[ x[i] ][ y[i]] += 1\n",
    "        \n",
    "        # Counts\n",
    "        n = len(x)\n",
    "        freq = Counter(y)\n",
    "        #print \"Numver of rows receieved \",n\n",
    "        #print n, freq_sum\n",
    "        freq_sum = sum( freq.values() )\n",
    "        unique_classes = freq.keys()\n",
    "        \n",
    "        # powersets\n",
    "        categories = set(x)\n",
    "        splits = getSplits(categories) if len(categories) > 1 else tuple(categories)\n",
    "        indexes = range(len(splits))\n",
    "        even_indices= [i for i in indexes if i %2 == 0] \n",
    "        \n",
    "        max_gain, max_gain_split = 0, []\n",
    "        # Dataset Entropy\n",
    "        entropy = 0\n",
    "        for k,v in freq.iteritems():\n",
    "            if v > 0:\n",
    "                p = float( v ) / freq_sum\n",
    "                entropy+= p*math.log(p,2)\n",
    "        entropy =  abs( entropy)\n",
    "        \n",
    "        #print entropy\n",
    "        #print \"Number of examples in x \", len(x)\n",
    "        best_dy_ent,  best_dn_ent =0,0\n",
    "        for i in even_indices:\n",
    "            dy_entropy =   calulate_entropies_categorical( splits[i], table, n , unique_classes )\n",
    "            # handling the case when only 1 tuple exists in powerset\n",
    "            if len( splits ) == 1:\n",
    "                dn_entropy = 0\n",
    "            else:\n",
    "                dn_entropy =  calulate_entropies_categorical( splits[i+1], table,n , unique_classes )\n",
    "\n",
    "            gain = entropy - (dy_entropy +dn_entropy)\n",
    "            #print \"DATASET ENTROP\", entropy  ,\"Gain = \", gain , \" DY\", dy_entropy, \" DN\", dn_entropy\n",
    "            #print \"==========================================\"\n",
    "            if gain > max_gain:\n",
    "                max_gain = gain\n",
    "                max_gain_split = splits[i]\n",
    "                best_dy_ent = dy_entropy\n",
    "                best_dn_ent = dn_entropy\n",
    "\n",
    "        #print \"BEST SCORE \", max_gain, \" AT SPLIT \", max_gain_split ,\"Entropy\", entropy ,\" Dy_ent\", best_dy_ent, \"dn_ent\",best_dn_ent\n",
    "        return max_gain, max_gain_split\n",
    "    \n",
    "    def evaluate_numerical_attribute(self,feat, Y ):\n",
    "        x =  feat.ravel()\n",
    "        y = Y.ravel()\n",
    "\n",
    "        # Counts\n",
    "        n = len(x)\n",
    "        freq = Counter(y)\n",
    "        freq_sum = sum( freq.values() )\n",
    "        #print \"Number of rows \", n\n",
    "        unique_classes = list(np.unique( Y ))\n",
    "\n",
    "        # k arg sort\n",
    "        sorted_indices = np.argsort(feat)\n",
    "        sorted_feature =  x[ sorted_indices ]\n",
    "        sorted_labels = y[sorted_indices]  \n",
    "\n",
    "        # datastructure\n",
    "        table = np.zeros( [ n ,len(unique_classes)] )\n",
    "        for i in xrange(len(sorted_feature)):\n",
    "            if i == 0:\n",
    "                table[0, unique_classes.index( sorted_labels[i] ) ] = 1\n",
    "            else:\n",
    "                prev = table[i-1 ] \n",
    "                table[i ] = prev        \n",
    "                table[i, unique_classes.index( sorted_labels[i] ) ] = prev[ unique_classes.index( sorted_labels[i] ) ] + 1\n",
    "\n",
    "        # Dataset Entropy\n",
    "        entropy = 0\n",
    "        for k,v in freq.iteritems():\n",
    "            if v > 0:\n",
    "                p = float( v ) / freq_sum\n",
    "                entropy+= p*math.log(p,2)\n",
    "        entropy =  abs( entropy)\n",
    "\n",
    "        #print freq\n",
    "        #print \"Entropy \" , entropy\n",
    "\n",
    "        max_gain, max_gain_split = 0, 0   \n",
    "        for i in  xrange( table.shape[0] ):\n",
    "            dy_entropy =  calulate_entropies_numerical( table[i], n )\n",
    "            dn = sub_vec( table[i], table[n-1] )\n",
    "            dn_entropy =  calulate_entropies_numerical( dn , n )\n",
    "            gain = entropy - (dy_entropy +dn_entropy)\n",
    "            if gain > max_gain:\n",
    "                # first check if the split point doesnt comes on later\n",
    "                \n",
    "                max_gain = gain\n",
    "                max_gain_split = sorted_feature[i]\n",
    "\n",
    "        return max_gain, max_gain_split\n",
    "    def __str__(self):\n",
    "        return self.__print(self.tree)        \n",
    "        \n",
    "     \n",
    "\n",
    "    def print_(self):\n",
    "        self.__print(self.tree)\n",
    "    def __print(self,node,depth=0):\n",
    "        ret = \"\"\n",
    "        # Print right branch\n",
    "        if node.rchild:\n",
    "            ret += self.__print(node.rchild,depth+1)\n",
    "        # Print own value\n",
    "        ret += \"\\n\" + (\"    \"*depth) + node.get_str()\n",
    "        # Print left branch\n",
    "        if node.lchild:\n",
    "            ret += self.__print(node.lchild,depth+1)\n",
    "        return ret    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education_num\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_weak\",\"native_country\",\"class\"]\n",
    "data = pd.read_csv( \"adult.data.txt\",names= col_names ,delimiter=',' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, validate, test = np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))])\n",
    "x_train=np.asarray(train[[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education_num\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_weak\",\"native_country\"]])\n",
    "y_train = np.asarray(train[['class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19536\n"
     ]
    }
   ],
   "source": [
    "print len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dt=DecisionTree(0.90,20)\n",
    "dt.train(x_train[:,:13], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            C(class= >50K,Purity=0.994694960212)\n",
      "        I(Fidx=10,Score=0.0667370407937,Split=5013)\n",
      "                C(class= >50K,Purity=0.968)\n",
      "            I(Fidx=11,Score=0.0465664344087,Split=1740)\n",
      "                            C(class= <=50K,Purity=0.958333333333)\n",
      "                        I(Fidx=2,Score=0.285286352008,Split=70387)\n",
      "                            C(class= >50K,Purity=1.0)\n",
      "                    I(Fidx=10,Score=0.0185066201989,Split=3103)\n",
      "                                    C(class= >50K,Purity=0.853801169591)\n",
      "                                I(Fidx=4,Score=0.0117058058791,Split=14)\n",
      "                                    C(class= >50K,Purity=0.756332931242)\n",
      "                            I(Fidx=12,Score=0.0194038432834,Split=35)\n",
      "                                    C(class= <=50K,Purity=0.560606060606)\n",
      "                                I(Fidx=0,Score=0.0694256001409,Split=47)\n",
      "                                    C(class= >50K,Purity=0.705882352941)\n",
      "                        I(Fidx=0,Score=0.018772240686,Split=36)\n",
      "                                    C(class= >50K,Purity=0.592964824121)\n",
      "                                I(Fidx=12,Score=0.0304833169893,Split=30)\n",
      "                                    C(class= <=50K,Purity=0.842105263158)\n",
      "                            I(Fidx=9,Score=0.0268141725569,Split=(' Female',))\n",
      "                                    C(class= <=50K,Purity=0.75)\n",
      "                                I(Fidx=2,Score=0.098133237363,Split=330132)\n",
      "                                    C(class= >50K,Purity=0.888888888889)\n",
      "                I(Fidx=6,Score=0.0364387719622,Split=(' Machine-op-inspct', ' Craft-repair', ' Other-service', ' Transport-moving', ' ?', ' Handlers-cleaners', ' Adm-clerical', ' Farming-fishing'))\n",
      "                            C(class= <=50K,Purity=1.0)\n",
      "                        I(Fidx=10,Score=0.0791592211673,Split=0)\n",
      "                                C(class= <=50K,Purity=0.75)\n",
      "                            I(Fidx=4,Score=0.0841487417504,Split=13)\n",
      "                                    C(class= <=50K,Purity=0.742268041237)\n",
      "                                I(Fidx=2,Score=0.0850431444492,Split=34007)\n",
      "                                    C(class= >50K,Purity=0.875)\n",
      "                    I(Fidx=6,Score=0.0238563422868,Split=(' Craft-repair', ' ?', ' Adm-clerical'))\n",
      "                                C(class= <=50K,Purity=1.0)\n",
      "                            I(Fidx=10,Score=0.0873356902283,Split=0)\n",
      "                                    C(class= <=50K,Purity=1.0)\n",
      "                                I(Fidx=11,Score=0.0739506346119,Split=0)\n",
      "                                    C(class= >50K,Purity=0.645569620253)\n",
      "                        I(Fidx=12,Score=0.0389324230008,Split=40)\n",
      "                                    C(class= >50K,Purity=0.727272727273)\n",
      "                                I(Fidx=4,Score=0.0337105895062,Split=14)\n",
      "                                    C(class= <=50K,Purity=0.567901234568)\n",
      "                            I(Fidx=12,Score=0.0277884342766,Split=6)\n",
      "                                C(class= <=50K,Purity=0.833333333333)\n",
      "    I(Fidx=4,Score=0.0957372993938,Split=12)\n",
      "            C(class= >50K,Purity=0.986254295533)\n",
      "        I(Fidx=10,Score=0.0720019358322,Split=5013)\n",
      "                                    C(class= >50K,Purity=0.711538461538)\n",
      "                                I(Fidx=11,Score=0.0141740645704,Split=1740)\n",
      "                                    C(class= <=50K,Purity=0.636062861869)\n",
      "                            I(Fidx=6,Score=0.0159175935246,Split=(' Other-service', ' Handlers-cleaners', ' Farming-fishing'))\n",
      "                                    C(class= <=50K,Purity=0.773885350318)\n",
      "                                I(Fidx=2,Score=0.0242409692558,Split=34973)\n",
      "                                    C(class= <=50K,Purity=1.0)\n",
      "                        I(Fidx=0,Score=0.0219661267922,Split=35)\n",
      "                                    C(class= <=50K,Purity=0.65625)\n",
      "                                I(Fidx=6,Score=0.0492609367247,Split=(' Other-service', ' Handlers-cleaners', ' Farming-fishing'))\n",
      "                                    C(class= <=50K,Purity=0.897435897436)\n",
      "                            I(Fidx=12,Score=0.0127618858374,Split=50)\n",
      "                                    C(class= <=50K,Purity=0.81204379562)\n",
      "                                I(Fidx=0,Score=0.0165797219995,Split=27)\n",
      "                                    C(class= <=50K,Purity=0.896373056995)\n",
      "                    I(Fidx=12,Score=0.017361818828,Split=35)\n",
      "                        C(class= <=50K,Purity=0.891737891738)\n",
      "                I(Fidx=4,Score=0.0249604234499,Split=8)\n",
      "                    C(class= <=50K,Purity=0.905339805825)\n",
      "            I(Fidx=6,Score=0.0310489915428,Split=(' Prof-specialty', ' Sales', ' Exec-managerial', ' Protective-serv', ' Adm-clerical', ' Tech-support'))\n",
      "                            C(class= <=50K,Purity=0.6)\n",
      "                        I(Fidx=11,Score=0.350742707785,Split=1977)\n",
      "                            C(class= >50K,Purity=1.0)\n",
      "                    I(Fidx=11,Score=0.0261665635834,Split=1844)\n",
      "                                    C(class= >50K,Purity=0.75)\n",
      "                                I(Fidx=1,Score=0.0510930356771,Split=(' Local-gov', ' Self-emp-not-inc', ' State-gov', ' Federal-gov', ' Self-emp-inc'))\n",
      "                                    C(class= <=50K,Purity=0.51724137931)\n",
      "                            I(Fidx=6,Score=0.036252162644,Split=(' Sales', ' Protective-serv', ' Adm-clerical'))\n",
      "                                    C(class= <=50K,Purity=0.684210526316)\n",
      "                                I(Fidx=1,Score=0.0746528120027,Split=(' Local-gov', ' Self-emp-not-inc', ' Federal-gov', ' Self-emp-inc'))\n",
      "                                    C(class= >50K,Purity=0.65)\n",
      "                        I(Fidx=4,Score=0.0218652835442,Split=10)\n",
      "                                    C(class= <=50K,Purity=1.0)\n",
      "                                I(Fidx=11,Score=0.0142954955479,Split=1485)\n",
      "                                    C(class= <=50K,Purity=0.541074249605)\n",
      "                            I(Fidx=12,Score=0.0269894138,Split=35)\n",
      "                                    C(class= <=50K,Purity=0.905405405405)\n",
      "                                I(Fidx=0,Score=0.0442800722163,Split=59)\n",
      "                                    C(class= <=50K,Purity=0.715517241379)\n",
      "                I(Fidx=0,Score=0.0271546052454,Split=31)\n",
      "                            C(class= <=50K,Purity=0.668539325843)\n",
      "                        I(Fidx=12,Score=0.0260073122564,Split=15)\n",
      "                            C(class= >50K,Purity=1.0)\n",
      "                    I(Fidx=0,Score=0.0415681169976,Split=28)\n",
      "                                    C(class= <=50K,Purity=0.794117647059)\n",
      "                                I(Fidx=6,Score=0.0501075913027,Split=(' Tech-support', ' Sales', ' Adm-clerical'))\n",
      "                                    C(class= <=50K,Purity=0.96)\n",
      "                            I(Fidx=3,Score=0.042218230721,Split=(' Assoc-acdm', ' Some-college', ' 11th'))\n",
      "                                    C(class= >50K,Purity=1.0)\n",
      "                                I(Fidx=1,Score=0.0409830104917,Split=(' Private', ' State-gov', ' Local-gov', ' Federal-gov'))\n",
      "                                    C(class= <=50K,Purity=0.717647058824)\n",
      "                        I(Fidx=0,Score=0.0442347002157,Split=24)\n",
      "                            C(class= <=50K,Purity=0.952380952381)\n",
      "I(Fidx=7,Score=0.154854170627,Split=(' Other-relative', ' Unmarried', ' Not-in-family', ' Own-child'))\n",
      "    C(class= <=50K,Purity=0.935166994106)\n"
     ]
    }
   ],
   "source": [
    "print dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test=np.asarray(test[[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education_num\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_weak\",\"native_country\"]])\n",
    "y_test = np.asarray(test[['class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = dt.test(x_test[:,:13]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "acc=  float( sum( z== y_test.ravel() ) ) / len(x_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy percantage:  85.1834791955\n"
     ]
    }
   ],
   "source": [
    "print \"Test set accuracy percantage: \" , acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hyperparameters\n",
    "n_examples = [ 5,10,15,20 ]\n",
    "purities = [ 80,85,90,95 ]\n",
    "depth = [5,10]\n",
    "acc_list = []\n",
    "best_nexamples , best_purities, best_depth , best_accuracy = 0,0,0,0\n",
    "for n in n_examples:\n",
    "    for p in purities:\n",
    "        for d in depth:\n",
    "            dt=DecisionTree(p,n,d)\n",
    "            dt.train(x_train[:,:13], y_train[:])\n",
    "            z = dt.test(x_test[:500,:13]  )\n",
    "            acc=  float( sum( z== y_test[:].ravel() ) ) / len(x_test[:]) * 100\n",
    "            acc_list.append(acc)\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_nexamples = n\n",
    "                best_purities = p\n",
    "                best_depth = d\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Accuracy \", best_accuracy, \" N_Example \" , best_nexamples, \" Purities \" , best_purities , \" Best_depth \" , best_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Best Run and Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix( actual, predicted ):\n",
    "    # calculate the confusion matrix; labels is numpy array of classification labels\n",
    "    confusion_matrix = np.zeros([2,2])\n",
    "    for a, p in zip(actual, predicted):\n",
    "        if a == ' <=50K':\n",
    "            if p == ' <=50K':\n",
    "                confusion_matrix[0][0] +=1\n",
    "            else:\n",
    "                confusion_matrix[0][1] +=1\n",
    "        else:\n",
    "            if p == ' <=50K':\n",
    "                confusion_matrix[1][0] +=1\n",
    "            else:\n",
    "                confusion_matrix[1][1] +=1\n",
    "    return confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt=DecisionTree(0.90,20)\n",
    "dt.train(x_train[:,:13], y_train[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = dt.test(x_test[:,:13]  )\n",
    "acc=  float( sum( z== y_test.ravel() ) ) / len(x_test) * 100\n",
    "conf_matrix = get_confusion_matrix( y_test.ravel(),z )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  85.1834791955\n",
      "[[ 4759.   194.]\n",
      " [  771.   789.]]\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy= \", acc\n",
    "print confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
